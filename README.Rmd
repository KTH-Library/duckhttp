---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```


# duckhttp

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![R-CMD-check](https://github.com/KTH-Library/duckhttp/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/KTH-Library/duckhttp/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

The goal of duckhttp is to provide functions to query and read responses from a duckdb server running the httpserver extension and/or from a server exposing data using Arrow Flight SQL. 

## Getting a connection

The section below shows how to ake a connection against the remote source, list tables and issue queries.

```{r connection}
#| eval: true

#install.packages("adbi")
#install.packages("adbcflightsql", repos = "https://community.r-multiverse.org")

library(duckhttp)

readRenviron("~/.Renviron")

# load a connectionstring of the format "https://user:pass@hostname:port/path/"
# perhaps from an environment variable in .Renviron
# then make a connection against that server

con <- duckhttp_con(Sys.getenv("CS_DEMETRIUS_HTTP"))

# to check that the service is up, use:
con |> duckhttp_ping()

# list the tables available
con |> duckhttp_ls()

# to issue custom SQL use (and read results converted from JSONCompact output)
con |> duckhttp_read("from topics limit 5")

# the same but reading CSV from the server
con |> duckhttp_read_csv("from topics limit 5")



# now load a connectionstring of the format "grpc://user:pass@hostname:port/"
# perhaps from an environment variable in .Renviron
# then make a connection against that server

con <- adbc_connect(Sys.getenv("CS_DEMETRIUS_FLIGHTSQL"))

# list tables available in the database
con |> adbc_tables()

# retrieve full table
con |> adbc_table("topics")

# issue a custom query
con |> adbc_query("from publishers limit 5")

# disconnect when done
adbc_disconnect(con)

```

# Backend notes

The enabled extensions in the remote duckdb instance can be utilized, including reading from further remote S3 instances etc. 

## Running a duckdb server instance with the httpserver extension

To get a duckdb server instance running locally serving data at the connectionstring used above, see instructions below. Please first see information about the httpserver extension available here:

<https://duckdb.org/community_extensions/extensions/httpserver.html>

In short start the server process at the command prompt like this:

```bash
DUCKDB_HTTPSERVER_FOREGROUND=1 DUCKDB_HTTPSERVER_DEBUG=1 duckdb -c "install httpserver from community; load httpserver; select httpserve_start('0.0.0.0', 8888, '');"
```

Then you can use the connectionstring "http://localhost:8888" for example

```{r localserver}
#| eval: false

library(duckhttp)

con <- duckhttp_con("http://localhost:8888")

query <- 
	" from 'https://shell.duckdb.org/data/tpch/0_01/parquet/orders.parquet' limit 5"

con |> duckhttp_read(query)

```


## Running a containerized "duckserve" instance

A duckdb server instance can also be run containerized with the httpserver extension to provide a JSON API for duckdb queries. An example setup configuration is described below.

- `Containerfile` defining the "duckserve" container 
- `compose.yaml` with a service composition including reverse proxy
- `serve.sql` a startup script for the "duckserve" service
  
The following Containerfile can be used to create a container image that runs duckdb CLI with the httpserver extension installed.

```Dockerfile
FROM debian:bookworm-slim

RUN apt update && apt install -y --no-install-recommends \
	wget \
	ca-certificates \
	unzip \
	procps

ENV DUCKDB_VER=v1.3.2

WORKDIR /usr/local/bin

RUN wget -O cli.zip "https://github.com/duckdb/duckdb/releases/download/$DUCKDB_VER/duckdb_cli-linux-amd6
4.zip" && \
	unzip cli.zip && rm cli.zip && chmod +x duckdb

WORKDIR /data

# get some standard example data into the database
RUN duckdb myduck.db 'CALL dbgen(sf=0.1); select 42;'

# get ability to read over http and s3
RUN duckdb myduck.db 'install httpfs; load httpfs;'

# get ability to serve api requests
RUN duckdb myduck.db 'install httpserver from community; load httpserver;'

# get ability to use read_parquet_mergetree
RUN duckdb myduck.db 'install chsql from community; load chsql;'

# get ability to work with json
RUN duckdb myduck.db 'install json; load json;'


VOLUME ["/data"]
EXPOSE 9999

CMD ["sh", "-c", "duckdb"]
```

The following `compose.yaml` file shows how such a container can be running as a service and how it can be reverse proxied:

```yaml

services:
  duckserve:
    image: duckserve
    command: duckdb -init serve.sql myduck.db
    environment:
      - DUCKDB_HTTPSERVER_DEBUG=1
      - DUCKDB_HTTPSERVER_FOREGROUND=1
    volumes:
      - ./serve.sql:/data/serve.sql:ro

  nginx:
    image: nginx:alpine
    volumes:
      - ./proxy.conf:/etc/nginx/conf.d/default.conf
    ports:
      - "80:80"


```

The "duckserve" service starts with an "init script", setting for example credentials providing access to relevant remote sources. Here is how such a "serve.sql" startup script can look like:

```sql

load httpfs;
load httpserver;
load json;

-- provide credentials
.mode trash
create secret (
	type S3,
	endpoint 'some.public.minio.s3.server.org',
	use_ssl 'true',
	url_style 'path',
	key_id 'some_secret_key',
	secret 'some_secret_passphrase'
);

.mode json

attach database 's3://mybucket/myduck.db' as mydb;

-- begin some sql statements here

-- end some sql statements here

SET disabled_filesystems = 'LocalFileSystem';

select httpserve_start('0.0.0.0', 9999, '');

```

To configure the reverse proxy, use a `proxy.conf` similar to this:

```
server {

	location /duckserve/ {
		proxy_redirect http://duckserve:9999 /duckserve/;
		proxy_pass http://duckserve:9999/;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;
	}

}
```

